<!DOCTYPE html>
<html lang="en">

<head>
   <!-- basic -->
   <meta charset="utf-8">
   <meta http-equiv="X-UA-Compatible" content="IE=edge">
   <!-- mobile metas -->
   <meta name="viewport" content="width=device-width, initial-scale=1">
   <meta name="viewport" content="initial-scale=1, maximum-scale=1">
   <!-- site metas -->
   <title>VisImages</title>
   <link rel = "icon" href =  
   "images/logo.png" 
      type = "image/x-icon"> 
   <meta name="keywords" content="">
   <meta name="description" content="">
   <meta name="author" content="">
   <!-- bootstrap css -->
   <link rel="stylesheet" href="css/bootstrap.min.css">
   <!-- style css -->
   <link rel="stylesheet" href="css/style.css">
   <!-- Responsive-->
   <link rel="stylesheet" href="css/responsive.css">
   <!-- fevicon -->
   <link rel="icon" href="images/fevicon.png" type="image/gif" />
   <!-- Scrollbar Custom CSS -->
   <link rel="stylesheet" href="css/jquery.mCustomScrollbar.min.css">
   <!-- Tweaks for older IEs-->
   <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.css"
      media="screen">
   <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
   <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
      </script>
   <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script><![endif]-->
</head>
<!-- body -->

<body class="main-layout">

   <!-- end loader -->
   <!-- header -->
   <header>
      <!-- header inner -->
      <div class="header">
         <div class="container">
            <div class="row">
               <div class="col-xl-3 col-lg-3 col-md-3 col-sm-3 col logo_section">
                  <div class="full">
                     <div class="center-desk">
                        <div class="logo">
                           <a href="index.html"><img src="images/logo.png" alt="#" /></a>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="col-xl-9 col-lg-9 col-md-9 col-sm-9">
                  <nav class="navigation navbar navbar-expand-md navbar-dark ">
                     <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample04"
                        aria-controls="navbarsExample04" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                     </button>
                     <div class="collapse navbar-collapse" id="navbarsExample04">
                        <ul class="navbar-nav mr-auto">
                           <li class="nav-item">
                              <a class="nav-link" href="#">VisImages</a>
                           </li>
                           <li class="nav-item2">
                              <a class="nav-link" href="http://www.visimages.org:3000/">Explorer</a>
                           </li>
                           <li class="nav-item2">
                              <a class="nav-link" href="https://github.com/VisImages/data">Download</a>
                           </li>
                        </ul>
                     </div>
                  </nav>
               </div>
            </div>
         </div>
      </div>
   </header>
   <!-- end header inner -->
   <!-- end header -->
   <!-- banner -->
   <section class="banner_main">
      <div id="banner1" class="carousel slide" data-ride="carousel">
         <ol class="carousel-indicators">
            <li data-target="#banner1" data-slide-to="0" class="active"></li>
            <li data-target="#banner1" data-slide-to="1"></li>
            <li data-target="#banner1" data-slide-to="2"></li>
            <li data-target="#banner1" data-slide-to="3"></li>
         </ol>
         <div class="carousel-inner">
            <div class="carousel-item active">
               <div class="container">
                  <div class="carousel-caption">
                     <div class="row d_flex">
                        <div class="col-md-6">
                           <div class="text-bg">
                              <h1> VisImages: A Corpus of Images from Visualization Publications</h1>
                              <p style="text-align: justify;">In this paper, we build and make public an image dataset from visualization publications with comprehensive samples and rich annotations. </p>
                              <a href="http://www.visimages.org:3000/">Explore the images</a>
                           </div>
                        </div>
                        <div class="col-md-6">
                           <div class="text_img">
                              <figure>
                                 <img src="images/pct1.png" alt="#" />
                              </figure>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
            </div>
            <div class="carousel-item ">
               <div class="container">
                  <div class="carousel-caption">
                     <div class="row d_flex">
                        <div class="col-md-6">
                           <div class="text-bg">
                              <h1> Pipeline</h1>
                              <p>During the process, we adopt a series of measures, such as gold standard, majority voting, and sampling test, to ensure the data correctness.</p>
                              <a href="#Methodology">Read More</a>
                           </div>
                        </div>
                        <div class="col-md-6">
                           <div class="text_img">
                              <figure>
                                 <img src="images/pct2.png" alt="#" />
                              </figure>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
            </div>
            <div class="carousel-item ">
               <div class="container">
                  <div class="carousel-caption">
                     <div class="row d_flex">
                        <div class="col-md-6">
                           <div class="text-bg">
                              <h1>Dataset</h1>
                              <p>We have obtained a dataset with 12,267 images from IEEE VAST and IEEE InfoVis images
                                 with 12,057 captions and 35,096 annotated boxes.</p>
                              <a href="#Dataset">Read More</a>
                           </div>
                        </div>
                        <div class="col-md-6">
                           <div class="text_img">
                              <figure>
                                 <img src="images/pct3.png" alt="#" />
                              </figure>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
            </div>
            <div class="carousel-item ">
               <div class="container">
                  <div class="carousel-caption">
                     <div class="row d_flex">
                        <div class="col-md-6">
                           <div class="text-bg">
                              <h1> Usage Scenarios </h1>
                              <p>We introduce four usage scenarios to show the usage of different data in VisImages.
                              </p>
                              <a href="#Scenario">Read More</a>
                           </div>
                        </div>
                        <div class="col-md-6">
                           <div class="text_img">
                              <figure>
                                 <img src="images/pct5.png" alt="#" />
                              </figure>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
            </div>

         </div>
      </div>
   </section>
   <!-- end banner -->
   <!-- team -->
   <div class="team">
      <div class="preface">
         <div class="container">
            <div class="row">
               <div class="col-md-10 offset-md-1">
                  <div class="titlepage">
                     <div id="preface">
                        <h2>Released Material</h2>
                        <p></p>
                        <!-- <div class="row"> -->
                        <h3>Codes</h3>
                        <p>
                        <ol style="decimal">
                           <li><a href="https://github.com/VisImages/visimages_explorer">VisImages Explorer</a></li>
                           <li><a href="https://github.com/VisImages/caption_tool">Caption Validation Tool</a></li>
                           <li><a href="https://github.com/VisImages/visimages_annotation">Image Annotation Interface</a></li>
                         </ol>
                        </p>
                         <p></p>
                        <h2>Abstract</h2>
                        <!-- <div class="row"> -->
                        <p>
                           Images in visualization publications contain rich information, e.g., novel visualization designs and common combinations of visualizations. A systematic collection of these images can contribute to the community in many aspects, such as literature analysis and automated tasks for visualization. In this paper, we build and make public a dataset, VisImages, which collects 12,267 images with captions from 1,397 papers in IEEE InfoVis and VAST. Based on a refined taxonomy for visualizations in publications, the dataset includes 35,096 annotated visualizations, as well as their positions. We demonstrate the usefulness of VisImages through three use cases: 1) exploring and analyzing the evolution of visualizations with VisImages Explorer, 2) training and benchmarking models for visualization classification, and 3) localizing and recognizing visualizations in the images automatically.
                        </p>
                        <!-- </div> -->
                        <!-- <div style="height:70px;"></div> -->
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </div>
      <!-- services -->
      <a name="Methodology"></a>
      <div class="Methodology">
         <div class="services">
            <div class="container">
               <!-- <div class="col-md-10 offset-md-1">
                  <i><img class="Methodology_img" src="images/a6.png" alt="#" /></i>
               </div> -->
               <div class="row">
                  <div class="col-md-10 offset-md-1">
                     <div id="serv_hover" class="titlepage">
                        <h2 class="Methodology_title">Pipeline</h2>
                        <p>To ensure the quality of annotation with limited professionals, we adopt a construction pipeline with carefully designed tasks and cross-validation procedures.We firstly build a taxonomy for visualization based on prior work and a multi-round pilot study.
                        With the taxonomy, we recruit senior visualization practitioners to annotate chart types and employ the crowd for bounding box annotation. </p>
                        <img src="images/a6.png" />
                     </div>
                  </div>
                  <div class="col-md-3">
                     <div id="serv_hover" class="sub_METHODOLOGY_box">
                        <i><img src="images/service1.png" alt="#" /></i>
                        <h3>Image Extraction</h3>
                     </div>
                  </div>
                  <div class="col-md-9">
                     <div id="serv_hover" class="sub_METHODOLOGY_box2">
                        <p>
                           In this study, we focused on 2D static visualizations and collected the images from VAST (IEEE Conference on Visual Analytics Science & Technology) and InfoVis (IEEE Conference on Information Visualization). We excluded SciVis (IEEE Conference on Scientific Visualization) papers since these papers generally comprise a large number of images depicting the results of 3D rendering, which are beyond the scope of our paper. 
                        </p>

                        <p>We borrowed a paper list from vispubdata.org, which has provided the title and digital object
                           identifier (DOI) of IEEE VIS papers. The vispubdata.org has assigned each paper a label among
                           <i>VIS</i>, <i>VAST</i>, <i>InfoVis</i>, and <i>SciVis</i>. We selected the papers with
                           the label of <i>VAST</i> and <i>InfoVis</i>.
                           <br>In total, we have processed <strong><span style="color:#fbb03b;">1397</span></strong>
                           papers in VAST and InfoVis from <strong><span style="color:#fbb03b;">1996</span></strong> to
                           <strong><span style="color:#fbb03b;">2018</span></strong>, and collected <strong><span
                                 style="color:#fbb03b;">12,267</span></strong> images with <strong><span
                                 style="color:#fbb03b;">12,057</span></strong> captions.
                        </p>
                     </div>
                  </div>
                  <div class="col-md-3">
                     <div id="serv_hover" class="sub_METHODOLOGY_box">
                        <i><img src="images/service2.png" alt="#" /></i>
                        <h3>Taxonomy</h3>
                     </div>
                  </div>
                  <div class="col-md-9">
                     <div id="serv_hover" class="sub_METHODOLOGY_box2">
                        <!-- <p><strong><span style="color:#fbb03b;">Preprocessing. </span></strong>During the taxonomy preprocessing, we annotated the visualization images from VAST and Info Vis in 2018 and 2010. After that, we have formed a taxonomy (Tpreprocessing) with 12 categories and 57 types.
                                  <br><strong><span style="color:#fbb03b;">Statistics. </span></strong>The participants are presented a series of visualization images, and requested to select the visualization types contained in the images.
                                  <br><strong><span style="color:#fbb03b;">Fine-tuning.</span></strong> To build a more balanced taxonomy with wide cover age,we fine-tuned the Tpreprocessing according to the results of statistics.
                               <br>Type Expansion.
                               <br>Type Merging.
                               <br>TypeDeletion.
                               <br>CategoryAdjustment.
                               <br>Finally, we have obtained a new taxonomy with 12 categories and 30 types.
                            </p> -->
                        <table>
                           <tr>
                              <th>Categories</th>
                              <th>Subtypes</th>
                           </tr>
                           <tr>
                              <td>Area</td>
                              <td>area chart, proportional area chart</td>
                           </tr>
                           <tr>
                              <td>Bar</td>
                              <td> bar chart </td>
                           </tr>
                           <tr>
                              <td>Circle </td>
                              <td> donut chart, pie chart, sector chart</td>
                           </tr>
                           <tr>
                              <td>Diagram</td>
                              <td> flow diagram, chord diagram, sankey diagram</td>
                           </tr>
                           <tr>
                              <td>Statistic</td>
                              <td>box plot, error bar, stripe graph</td>
                           </tr>
                           <tr>
                              <td>Grid</td>
                              <td> matrix, table, small multiple</td>
                           </tr>
                           <tr>
                              <td>Line</td>
                              <td> line chart, storyline, polar plot, parallel coordinate
                              </td>
                           </tr>
                           <tr>
                              <td>Map</td>
                              <td> map</td>
                           </tr>
                           <tr>
                              <td>Point</td>
                              <td>scatter plot</td>
                           </tr>
                           <tr>
                              <td>Units&Glyph</td>
                              <td> heatmap, glyph-based visualization, unit visualization</td>
                           </tr>
                           <tr>
                              <td>Word</td>
                              <td>word cloud</td>
                           </tr>
                           <tr>
                              <td>Tree&Graph </td>
                              <td> graph, tree, treemap, hierarchical edge bundling, sunburst/icicle chart </td>
                           </tr>
                        </table>
                        <!-- <img class="Taxonomy" src="images/table.png"> -->
                     </div>
                  </div>
                  <div class="col-md-3">
                     <div id="serv_hover" class="sub_METHODOLOGY_box">
                        <i><img src="images/service3.png" alt="#" /></i>
                        <h3>Visualization Type Annotation</h3>
                     </div>
                  </div>
                  <div class="col-md-9">
                     <div id="serv_hover" class="sub_METHODOLOGY_box2">
                        <p> Distinguishing visual representations and their variations is challenging and requires extensive knowledge in visualization. To ensure quality, we recruit senior visualization practitioners to annotate the subtypes (step B and C in the pipeline). 
                           <br><strong><span style="color:#fbb03b;">Participants.</span></strong> We recruited 25
                           senior visualization practitioners for visualization type annotation.
                           <br><strong><span style="color:#fbb03b;">Task and Design.</span></strong> We designed a multi-label task for type annotation. We first developed an interface for the annotation tasks. The interface contained buttons for 30 different subtypes and a “submit” button. Besides, we provided an “others” category for exceptional cases.
                        </p>
                        <img class="Taxonomy" src="images/interface.png">
                     </div>
                  </div>
                  <div class="col-md-3">

                     <div id="serv_hover" class="sub_METHODOLOGY_box">
                        <i><img src="images/service4.png" alt="#" /></i>
                        <h3>Bounding Box Annotation</h3>
                     </div>
                  </div>
                  <div class="col-md-9">
                     <div id="serv_hover" class="sub_METHODOLOGY_box2">
                        <p> We employed the crowd from a data annotation company, whose workers are well-trained for similar tasks (step D in the pipeline). 
                           <br><strong><span style="color:#fbb03b;">Tasks.</span></strong> The challenge of drawing bounding boxes in our scenario is to recognize various visual representations and their variations. To reduce the mental load, each crowd worker was guided to focus on only one subtype. Each task included an image containing this specific subtype and a request to draw the bounding boxes around all visualizations of this subtype.
                           <!-- <br><strong><span style="color:#fbb03b;">Criteria. </span></strong>For each single
                           visualization, the bounding box should include all visible part of that visualization and be
                           as tight as possible. -->
                           <br><strong><span style="color:#fbb03b;">Quality Control.</span></strong>  For quality control, we adopted a sampling test on both batch level and worker level. We equally divided the 10,289 images into five batches and performed annotations batch by batch. The batch level sampling test was performed after completing a batch of annotations. We randomly sampled 10% of the results and evaluated the F1 score. If the F1 score was not higher than 95%, the whole batch of annotation would be rejected. The rejected batch would be annotated again until the F1 score reached 95%. The worker level sampling test was conducted during one batch of annotations, where 15% annotations of a worker would be randomly sampled for F1 score evaluation. If the F1 score was not higher than 95%, all finished tasks of this worker in this batch would be rejected and annotated again. For the workers who failed the sampling test, their sampling rate would increase by 5% at the next test.
                           <!-- <br><strong><span style="color:#fbb03b;">Procedure & Results.</span></strong> We provided the
                           10,289images with visualization type annotations, and the annotation team would submit the
                           bounding box annotatons in four times. After the ﬁrst round of annotation, crowd workers
                           became familiar to the criteria and deﬁnitions, and the following three rounds of annotations
                           achieved 95.67%, 97.67%, and 97.39% F1 score. Finally, we have obtained 35,356bounding boxes. -->
                        </p>
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </div>
      <!-- end services -->
      <a name="Dataset"></a>
      <div class="container">
         <div class="Dataset1">
            <div class="row d_flex">

               <div class="col-md-6">
                  <div class="titlepage">
                     <h2>Dataset</h2>
                     <p>We obtain a dataset with 12,267 images from IEEE VAST and IEEE InfoVis images with 12,057
                        captions and 35,096 annotated boxes.</p>
                     <a class="read_more" href="https://github.com/VisImages/data">Download the Dataset</a>
                  </div>
               </div>
               <div class="col-md-5 offset-md-1">
                  <div id="visimage" class="team_img">
                     <figure><img src="images/sco.png" alt="#" /></figure>
                  </div>
               </div>
            </div>
         </div>
         <div class="container">
            <div class="row d_flex">
               <!-- <div class="col-md-9"> -->
               <div class="row">
                  <div id="serv_hover" class="sub_METHODOLOGY_box2">
                     <div class="col-md-12" style="margin-left: auto;margin-right: auto;">
                        <figure><img src="images/fig4.png" alt="#" /></figure>
                     <p>Distribution of the visualization subtypes. The internal bars show the numbers of images containing each subtype, and the external bars show the numbers of bounding boxes of each subtype.</p>
                     </div>
                  </div>
               </div>
               <div class="row">
                  <div id="serv_hover" class="sub_METHODOLOGY_box2">
                     <div class="col-md-12">
                        <figure><img src="images/fig5.png" alt="#" /></figure>
                        <p> Comparison of the distribution of visualization categories from visualization publications,
                           scientific publications, infographics, news media, and government and world organization. The
                           data of the sources in light blue comes from the work of Borkin et al.</p>
                     </div>
                  </div>
               </div>
               <div class="row">
                  <div id="serv_hover" class="sub_METHODOLOGY_box2">
                     <div class="col-md-12" style="margin-left: auto;margin-right: auto;">
                        <figure><img src="images/fig6.png" alt="#" /></figure>
                     <p> To analyze the evoluation of each visualization type, we counted the average number of the bounding boxes of each visualization type in the paper and visualized the distribution with horizon charts.
                     The horizon charts were vertically aligned according to years, and horizontally aligned with a same height of 2. The darker the color, the larger the average number of the visualization.</p>
                     </div>
                  </div>
               </div>
               <div class="row">
                  <div id="serv_hover" class="sub_METHODOLOGY_box2">
                     <div class="col-md-12">
                        <figure><img src="images/fig7.png" alt="#" /></figure>
                        <p> To measure the differences between visualization subtypes, we borrow the idea of confusion matrix from the machine learning field to revisit our taxonomy.
                           The confusion matrix describes how easily people get confused about two visualization subtypes in the course of annotation. Specifically, for two subtypes a and b, we first counted the number of images that were annotated with visualization a or b in VisImages.
                           We examine their raw annotation data during the process of visualization type annotation, where three annotators labelled all the possible visualization subtypes in the images and the subtypes selected by at least two annotators were finally accepted. That is, there exist examples which were not unanimously annotated as a subtype, indicating an inconsistency among the annotators. We model this inconsistency as confusion between visualization subtypes. 
                           Therefore, the confusion score between subtypes a and b was calculated as follows:
                           $$Score_{a,b}=1 - P(a\in\mathbb{S}\wedge b\in\mathbb{S}|a\in\mathbb{C}\wedge b\in\mathbb{C}),$$
                           where \(\mathbb{C}\) and \(\mathbb{S}\) represent the set of selected types before and after the majority voting, respectively. </p>
                     </div>
                  </div>
               </div>
               </div>
            </div>
         </div>
      </div>
      <!-- team -->
      <!-- New Ideas  section -->
      <a name="Scenario"></a>
      <div class="ideas">
         <div class="yellow_darkbg">
            <div class="container">
               <div class="row">
                  <div class="col-md-12">
                     <div class="titlepage">
                        <h2>Use Cases</h2>
                        <!-- <a class="read_more" href="#">Read More</a> -->
                     </div>
                  </div>
               </div>
            </div>
         </div>
         <!-- blog -->
         <div class="blog">
            <div class="container">
               <div class="row">
                  <div class="col-md-12">
                     <div class="blog_box">
                        <h3>VisImages Explorer for Exploring and Analyzing the Evolution of Visualizations</h3>
                        <figure><img src="images/explorer.png" alt="#" /></figure>
                        <p><br>VisImages Explorer. (A) is the search panel for keyword searching by the title and filtering by year, author, and conference. (B) is the image gallery displaying the images contained in the papers. (C) is the visualization streams showing the distribution of different visualizations across years. (D) is the caption clouds exhibiting the frequently occurring words in the captions of the filtered images. (E) and (F) show the visualization streams and caption clouds after selecting ''VAST" in the search panel, respectively. </br>
                        </p>
                     </div>
                  </div><div class="col-md-14">
                     <div class="blog_box">
                        <h3>VisImages Classification</h3>
                        <figure ><img src="images/classfication.png" width="500" height="600" alt="#"/></figure>
                        <p><br>In this case, we show how VisImages can benefit visualization classification which has been adopted in many scenarios, such as visualization reconstruction and empirical studies. We first report the performance of the models on classifying visualizations with VisImages on two levels, namely, the category level (V-12) and the subtype level (V-30). We then compare VisImages with existing datasets to demonstrate the advantage of VisImages for visualization classification. Since a visualization can have multiple classes, we use both top-1 accuracy and top-3 accuracy as evaluation metrics.</br>
                        </p>
                     </div>
                  </div><div class="col-md-12">
                     <div class="blog_box">
                        <figure><img src="images/case4_single.png" alt="#" /></figure>
                        <h3>Visualization Detection on VisImages</h3>
                        <p><br>Results of visualization detection with Faster R-CNN. (A) shows an example of table visualization. (B) and (C) show the predicted examples of the visualizations composed of multiple visualization types. (D) presents the cases of heatmaps and bar charts. (D1) and (D2) are recognized as heatmaps. (D3) shows the successfully recognized bar charts, and (D4) indicates the position of the bar charts that are proposed to predict but fail.</br>
                        </p>
                     </div>
                  </div>
                  <div class="col-md-12">
                     <div class="blog_box">
                        <h3>Evolution of Color Used in VAST and InfoVis</h3>
                        <figure><img src="images/s1.png" alt="#" /></figure>
                        <p><br>The images are represented in <span style="color:#fbb03b;">CIELAB </span>color space, in
                           which the color change is compatible to the human perception change.
                           The <span style="color:#fbb03b;">CIELAB </span>color space is composed of <span
                              style="color:#fbb03b;">3 </span>dimensions. We divide each dimension into five bins and
                           obtain a discrete color space with <span style="color:#fbb03b;">5×5×5 = 125</span> color
                           values.For the images, we count the pixel number of each color value. </br>
                        </p>
                     </div>
                  </div>

                  <div class="col-md-12">
                     <div class="blog_box">
                        <h3>Visualization Types Preference of the Top Researchers</h3>
                        <figure><img src="images/s2.png" alt="#" /></figure>
                        <p><br>We explore the visualization preference of the top researchers in visualization community.
                           Here, different colors represent different types of visualization. And researchers' preferences are related to their research topics.</br></p>
                     </div>
                  </div>
                  <div class="col-md-12">
                     <div class="blog_box">
                        <h3>Spatial Distribution of Visualizations in VA Systems</h3>
                        <figure><img src="images/s3.png" alt="#" /></figure>
                        <p><br><span style="color:#fbb03b;">Firstly</span>, retrieve the images from the captions with the keywords “interface” and “system overview,” and build a caption classification dataset with two categories, i.e., "interface" and "others."
                           <span style="color:#fbb03b;">Secondly</span>, we adopt term frequency-inverse document frequency (TF-IDF) to train a support vector
                           machine (SVM) to classify the captions of “interface.”
                           <span style="color:#fbb03b;">Finally</span>, plot the bounding boxes of each visualization types on the canvases and obtain the heatmaps.</br></p>
                     </div>
                  </div>

               </div>
            </div>
         </div>
      </div>

   </div>
   <!-- end New Ideas  section -->
   <!--  footer -->
   <footer>
      <div class="footer">
         <div class="copyright">
            <div class="container">
               <p>Copyright &copy VisImages</p>
            </div>
         </div>
      </div>
   </footer>
   <!-- end footer -->
   <!-- Javascript files-->
   <script src="js/jquery.min.js"></script>
   <script src="js/popper.min.js"></script>
   <script src="js/bootstrap.bundle.min.js"></script>
   <script src="js/jquery-3.0.0.min.js"></script>
   <!-- sidebar -->
   <script src="js/jquery.mCustomScrollbar.concat.min.js"></script>
   <script src="js/custom.js"></script>
</body>

</html>
